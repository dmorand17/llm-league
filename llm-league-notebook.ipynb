{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06242e4-5012-4cad-b5a7-ec83facc3c97",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning Llama 3.2 3B Instruct with SageMaker JumpStart\n",
    "\n",
    "This notebook demonstrates how to fine-tune Meta's Llama 3.2 3B Instruct model using Amazon SageMaker JumpStart. We'll use a small dataset (around 100 examples) and parameter-efficient fine-tuning techniques like LoRA/QLoRA.\n",
    "\n",
    "Hugging face model card: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6d57a-8b74-4e4d-944c-7d082f436e61",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "First, let's set up our SageMaker environment and install any required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21685c9a-3f72-48eb-bc4f-2874b0cead88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcacf15-fb4f-42b6-9c2b-3850b5e99b03",
   "metadata": {},
   "source": [
    "# Get list of Hugging Face\n",
    "\n",
    "Use the following code to get a revision listing for models on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca5bb2-70aa-49ab-929c-83a72d808020",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c03c9e-ab0b-4969-94c6-f899379c7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_TOKEN=\"<insert your token here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571277c-2762-4f6b-a1a0-2f3ac0120289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print environment variables\n",
    "!echo $HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553db164-592b-4192-a057-0e4a156ad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all environment variables\n",
    "# !env\n",
    "for key, value in os.environ.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17a12f-6fc3-4d16-a762-9678ee63a9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, whoami, login\n",
    "import os\n",
    "\n",
    "# access_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Or configure a HfApi client\n",
    "api = HfApi(\n",
    "    endpoint=\"https://huggingface.co\", # Can be a Private Hub endpoint.\n",
    "    token=\"<insert your token here>\", # Token is not persisted on the machine.\n",
    ")\n",
    "# models = api.list_models()\n",
    "# for model in models:\n",
    "#     print(model)\n",
    "\n",
    "# access_token = os.getenv(\"HF_TOKEN\") # API_KEY environment variable\n",
    "\n",
    "# login(token=access_token)\n",
    "user = whoami(token=\"<insert your token here>\")\n",
    "print(access_token)\n",
    "\n",
    "# model_name = \"olmo-7B\"\n",
    "model_name = \"meta-textgeneration-llama-3-2-3b-instruct\"\n",
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_name = \"google-bert/bert-base-cased\"\n",
    "\n",
    "refs = api.list_repo_refs(model_name)\n",
    "for branch in refs.branches:\n",
    "    name = branch.name\n",
    "    print(f\"branch: {name}\")\n",
    "\n",
    "# revisions = api.list_revisions(model_name)\n",
    "# for revision in revisions:\n",
    "#     print(f\"revision: {revision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e93ed-d72f-4c2b-9036-6a51e1223a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize SageMaker session\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role() # This should only be run on notebook instances\n",
    "region = session.boto_region_name\n",
    "# S3 bucket for storing data and model artifacts\n",
    "default_bucket = session.default_bucket()\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"AWS Region: {region}\")\n",
    "print(f\"Default S3 Bucket: {default_bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d32258-6b0a-4940-8647-2e766ed38420",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"league-of-llm-internal-bucket-group3\"\n",
    "prefix = \"domorand\"\n",
    "training_object = \"2025-03-12-dataset.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1714f8-98d7-422d-8000-32d4552ea709",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training_object = {training_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eebb70f-e01b-420b-b704-40ce1d0d3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "def run_llama_finetuning(job_name, training_object, hyperparameters=None):\n",
    "    \"\"\"\n",
    "    Run a fine-tuning job for Llama 3.2 3B Instruct model using SageMaker JumpStart.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Upload training data to S3\n",
    "    # training_data_path = \"path/to/local/training_data.jsonl\"  # Update this path\n",
    "    s3_training_data_path = f\"s3://{bucket}/{prefix}/dataset/{training_object}\"\n",
    "    logger.info(f\"s3_training_data_path={s3_training_data_path}\")\n",
    "    # try:\n",
    "    #     logger.info(f\"Uploading training data to {s3_training_data_path}\")\n",
    "    #     boto3.Session().resource('s3').Object(\n",
    "    #         bucket, \n",
    "    #         \"llama3-finetuning/data/training_data.jsonl\"\n",
    "    #     ).upload_file(training_data_path)\n",
    "    # except Exception as e:\n",
    "    #     logger.error(f\"Error uploading training data: {str(e)}\")\n",
    "    #     raise\n",
    "\n",
    "    # Set output path\n",
    "    output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "    \n",
    "    # Create SageMaker JumpStart estimator\n",
    "    estimator = JumpStartEstimator(\n",
    "        model_id=model_id,\n",
    "        model_version=model_version,\n",
    "        instance_type=\"ml.g5.12xlarge\",  # GPU instance with good memory\n",
    "        instance_count=1,\n",
    "        hyperparameters=hyperparameters,\n",
    "        role=role,\n",
    "        output_path=output_path,\n",
    "        environment={\"accept_eula\": \"true\"},\n",
    "        volume_size=256\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created JumpStart estimator for {model_id}\")\n",
    "    logger.info(f\"Parameters {hyperparameters}\")\n",
    "    \n",
    "    # Configure input data channel\n",
    "    train_data = {\"training\": s3_training_data_path}\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Starting fine-tuning job: {job_name}\")\n",
    "        estimator.fit(\n",
    "            train_data,\n",
    "            job_name=job_name,\n",
    "            # accept_eula=True,\n",
    "            wait=False,  # Set to True if you want to wait for the job to complete\n",
    "            logs=False   # Set to True if you want to see logs\n",
    "        )\n",
    "        logger.info(f\"Training job started: {job_name}\")\n",
    "        print(f\"Training job '{job_name}' started!\")\n",
    "        print(f\"You can monitor the job in the SageMaker console or run 'estimator.latest_training_job.wait()' to wait for completion\")        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error starting training job: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return {\n",
    "        \"job_name\": job_name,\n",
    "        \"model_data_s3_path\": f\"{output_path}/{job_name}/output/model.tar.gz\",\n",
    "        \"training_job_arn\": estimator.latest_training_job.job_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1493cf-3b3d-4b1b-a5ee-3f004c2169ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model ID for Llama 3.2 3B Instruct\n",
    "model_id = \"meta-textgeneration-llama-3-2-3b-instruct\"\n",
    "# model_version = \"1.*\"  # Update this version as needed\n",
    "model_version = \"*\"  # Update this version as needed\n",
    "# model_version = \"1.0.0\"  # Update this version as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d1f2a-ba59-4515-b47e-eb5f1119fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default hyperparameters for model\n",
    "from sagemaker import hyperparameters\n",
    "\n",
    "params = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "print(f\"Default parameters: \\n {json.dumps(params, indent=2)}\")\n",
    "\n",
    "# Learning rates to try\n",
    "# 0.00002 = 2e-4\n",
    "# 0.00001 = 1e-4\n",
    "# 0.0001 = 1e-3\n",
    "# 0.0002 = 2e-3\n",
    "\n",
    "# Optionally override default hyperparameters for fine-tuning\n",
    "\n",
    "# Required for all training jobs\n",
    "params[\"chat_dataset\"] = \"False\"\n",
    "params[\"instruction_tuned\"] = \"True\"\n",
    "\n",
    "# optional parameters to get better results...\n",
    "\n",
    "# params[\"epoch\"] = \"3\"\n",
    "# params[\"learning_rate\"] = \"2e-4\" \n",
    "# params[\"per_device_train_batch_size\"] = \"2\"\n",
    "# params[\"lora_r\"] = \"16\"\n",
    "# params[\"lora_alpha\"] = \"16\"\n",
    "# params[\"lora_dropout\"] = \"0.05\"\n",
    "\n",
    "### Try 2\n",
    "\n",
    "params[\"epoch\"] = \"12\"\n",
    "params[\"learning_rate\"] = \"2e-3\"\n",
    "params[\"per_device_train_batch_size\"] = \"4\"\n",
    "params[\"lora_r\"] = \"64\"\n",
    "params[\"lora_alpha\"] = \"128\"\n",
    "params[\"lora_dropout\"] = \"0.05\"\n",
    "\n",
    "params = {\n",
    "    \"chat_dataset\": False,\n",
    "    \"instruction_tuned\": True,\n",
    "    \"epoch\": 8,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"lora_r\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.1\n",
    "}\n",
    "\n",
    "# Validate parameters\n",
    "print(\"Validating hyperparameters...\")\n",
    "hyperparameters.validate(model_id=model_id, model_version=model_version, hyperparameters=params) # Throws error if not valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61d5d7-578e-4f9a-b34d-7f9b107ddbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Get the current timestamp\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the timestamp as 'YYYYMMddHHmm'\n",
    "formatted_timestamp = current_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "response = run_llama_finetuning(f\"group3-domorand-model-{formatted_timestamp}\",\n",
    "                                \"2025-03-12-dataset.jsonl\", \n",
    "                                hyperparameters=params)\n",
    "print(f\"response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f269d-9b13-4d2c-b17a-ed75565f11d5",
   "metadata": {},
   "source": [
    "# Troubleshooting\n",
    "\n",
    "## How to get previous job hyper parameters\n",
    "\n",
    "This can be useful when debugging previous jobs or to inspect hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38acc3-c53f-4446-97ea-2140a51d0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the training job name\n",
    "# training_job_name = 'group3-domorand-model13'\n",
    "training_job_name = 'group3-domorand-model-202503130308'\n",
    "\n",
    "# Describe the training job\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "# Access hyperparameters\n",
    "# Pretty print the response\n",
    "print(json.dumps(response, indent=4, default=str))\n",
    "# print(response)\n",
    "# print(json.dumps(response['HyperParameters'], indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
