{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06242e4-5012-4cad-b5a7-ec83facc3c97",
   "metadata": {},
   "source": [
    "# Fine-tuning Llama 3.2 3B Instruct with SageMaker JumpStart\n",
    "\n",
    "This notebook demonstrates how to fine-tune Meta's Llama 3.2 3B Instruct model using Amazon SageMaker JumpStart. We'll use a small dataset (around 100 examples) and parameter-efficient fine-tuning techniques like LoRA/QLoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6d57a-8b74-4e4d-944c-7d082f436e61",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "First, let's set up our SageMaker environment and install any required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21685c9a-3f72-48eb-bc4f-2874b0cead88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.11/site-packages (2.241.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.37.11)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.115.8)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.22)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.34.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.11 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.37.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.38.0,>=1.37.11->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from omegaconf<=2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.23.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (2025.1.31)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (0.45.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.70.17)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.11/site-packages (from starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (4.8.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a96e93ed-d72f-4c2b-9036-6a51e1223a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role: arn:aws:iam::482018956800:role/MonitoringStack-SageMakerExecutionRole7843F3B8-7FDMd6X85xyx\n",
      "AWS Region: us-east-1\n",
      "Default S3 Bucket: league-of-llm-internal-bucket-group3\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize SageMaker session\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role() # This should only be run on notebook instances\n",
    "region = session.boto_region_name\n",
    "# S3 bucket for storing data and model artifacts\n",
    "# bucket = session.default_bucket()\n",
    "\n",
    "# bucket = \"league-of-llm-internal-bucket-group3\"\n",
    "# prefix = \"domorand\"\n",
    "# training_data = \"2025-03-12-dataset.jsonl\"\n",
    "\n",
    "print(f\"SageMaker Role: {role}\")\n",
    "print(f\"AWS Region: {region}\")\n",
    "print(f\"Default S3 Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39d32258-6b0a-4940-8647-2e766ed38420",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"league-of-llm-internal-bucket-group3\"\n",
    "prefix = \"domorand\"\n",
    "training_object = \"2025-03-12-dataset.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1714f8-98d7-422d-8000-32d4552ea709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_object = 2025-03-12-dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(f\"training_object = {training_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eebb70f-e01b-420b-b704-40ce1d0d3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llama_finetuning(job_name, training_object, hyperparameters):\n",
    "    \"\"\"\n",
    "    Run a fine-tuning job for Llama 3.2 3B Instruct model using SageMaker JumpStart.\n",
    "    \"\"\"\n",
    "    # Define model ID for Llama 3.2 3B Instruct\n",
    "    model_id = \"meta-textgeneration-llama-3-2-3b-instruct\"\n",
    "    # model_version = \"1.0.0\"  # Update this version as needed\n",
    "    \n",
    "    # Upload training data to S3\n",
    "    # training_data_path = \"path/to/local/training_data.jsonl\"  # Update this path\n",
    "    s3_training_data_path = f\"s3://{bucket}/{prefix}/dataset/{training_object}\"\n",
    "    logger.info(f\"s3_training_data_path={s3_training_data_path}\")\n",
    "    # try:\n",
    "    #     logger.info(f\"Uploading training data to {s3_training_data_path}\")\n",
    "    #     boto3.Session().resource('s3').Object(\n",
    "    #         bucket, \n",
    "    #         \"llama3-finetuning/data/training_data.jsonl\"\n",
    "    #     ).upload_file(training_data_path)\n",
    "    # except Exception as e:\n",
    "    #     logger.error(f\"Error uploading training data: {str(e)}\")\n",
    "    #     raise\n",
    "\n",
    "    # Set output path\n",
    "    output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "    \n",
    "    # Create SageMaker JumpStart estimator\n",
    "    estimator = JumpStartEstimator(\n",
    "        model_id=model_id,\n",
    "        # model_version=model_version,\n",
    "        instance_type=\"ml.g5.12xlarge\",  # GPU instance with good memory\n",
    "        instance_count=1,\n",
    "        hyperparameters=hyperparameters,\n",
    "        role=role,\n",
    "        output_path=output_path,\n",
    "        volume_size=256\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Created JumpStart estimator for {model_id}\")\n",
    "    logger.info(f\"Parameters {hyperparameters}\")\n",
    "    \n",
    "    # Configure input data channel\n",
    "    train_data = {\"train\": s3_training_data_path}\n",
    "    \n",
    "    \n",
    "    # Start training job\n",
    "    # job_name = f\"group3-domorand-model14\"\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Starting fine-tuning job: {job_name}\")\n",
    "        estimator.fit(\n",
    "            train_data,\n",
    "            job_name=job_name,\n",
    "            accept_eula=True,\n",
    "            wait=False,  # Set to True if you want to wait for the job to complete\n",
    "            logs=False   # Set to True if you want to see logs\n",
    "        )\n",
    "        logger.info(f\"Training job started: {job_name}\")\n",
    "        print(f\"Training job '{job_name}' started!\")\n",
    "        print(f\"You can monitor the job in the SageMaker console or run 'estimator.latest_training_job.wait()' to wait for completion\")        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error starting training job: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return {\n",
    "        \"job_name\": job_name,\n",
    "        \"model_data_s3_path\": f\"{output_path}/{job_name}/output/model.tar.gz\",\n",
    "        \"training_job_arn\": estimator.latest_training_job.job_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b03d1f2a-ba59-4515-b47e-eb5f1119fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Define hyperparameters\n",
    "    initial_hyperparameters = {\n",
    "        # Training parameters\n",
    "        \"epoch\": \"3\",                  # Number of training epochs\n",
    "        \"learning_rate\": \"1e-2\",       # Learning rate .01\n",
    "        \"per_device_train_batch_size\": \"2\",  # Batch size per GPU for training\n",
    "        # \"per_device_eval_batch_size\": \"2\",   # Batch size per GPU for evaluation\n",
    "        \"gradient_accumulation_steps\": \"2\",  # Number of steps to accumulate gradients\n",
    "        # \"warmup_steps\": \"10\",          # Number of warmup steps for learning rate scheduler\n",
    "        # \"weight_decay\": \"0.01\",        # Weight decay\n",
    "        \"chat_dataset\": False,\n",
    "        \"instruction_tuned\": True,\n",
    "        # \"target_modules\": \"q_proj,v_proj\",\n",
    "        # \"int8_quantization\": False,\n",
    "        \n",
    "        # LoRA specific parameters\n",
    "        \"use_lora\": \"True\",            # Use LoRA for fine-tuning\n",
    "        \"lora_r\": \"16\",                # LoRA attention dimension\n",
    "        \"lora_alpha\": \"32\",            # LoRA alpha parameter\n",
    "        \"lora_dropout\": \"0.05\",        # Dropout probability for LoRA layers\n",
    "        \n",
    "        # QLoRA specific parameters (for memory efficiency)\n",
    "        # \"use_qlora\": \"True\",           # Use QLoRA for more memory efficiency\n",
    "        # \"bnb_4bit_quant_type\": \"nf4\",  # Quantization type\n",
    "        # \"bnb_4bit_compute_dtype\": \"float16\",  # Compute dtype\n",
    "        \n",
    "        # Other settings\n",
    "        # \"max_seq_length\": \"2048\",      # Maximum sequence length\n",
    "        # \"save_strategy\": \"epoch\",      # Save strategy\n",
    "        # \"evaluation_strategy\": \"epoch\" # Evaluation strategy\n",
    "    }\n",
    "\n",
    "    small_dataset_1_hyperparameters = {\n",
    "        # Training parameters\n",
    "        \"epoch\": \"3\",                  # Number of training epochs\n",
    "        \"learning_rate\": \"0.00002\",       # Learning rate 2e-4\n",
    "        \"per_device_train_batch_size\": \"4\",  # Batch size per GPU for training\n",
    "        # \"per_device_eval_batch_size\": \"2\",   # Batch size per GPU for evaluation\n",
    "        \"gradient_accumulation_steps\": \"2\",  # Number of steps to accumulate gradients\n",
    "        # \"warmup_steps\": \"10\",          # Number of warmup steps for learning rate scheduler\n",
    "        # \"weight_decay\": \"0.01\",        # Weight decay\n",
    "        \"chat_dataset\": False,\n",
    "        \"instruction_tuned\": True,\n",
    "        # \"target_modules\": \"q_proj,v_proj\",\n",
    "        # \"int8_quantization\": False,\n",
    "        # LoRA specific parameters\n",
    "        # \"use_lora\": \"True\",            # Use LoRA for fine-tuning\n",
    "        \"lora_r\": \"16\",                # LoRA attention dimension\n",
    "        \"lora_alpha\": \"32\",            # LoRA alpha parameter\n",
    "        \"lora_dropout\": \"0.05\",        # Dropout probability for LoRA layers\n",
    "        \n",
    "        # QLoRA and PEFT parameters (for memory efficiency)\n",
    "        # \"use_qlora\": \"True\",           # Use QLoRA for more memory efficiency\n",
    "        # \"use_bnb_4bit\": \"True\",  # Quantization type\n",
    "        \n",
    "        # Other settings\n",
    "        # \"max_seq_length\": \"2048\",      # Maximum sequence length\n",
    "        # \"save_strategy\": \"epoch\",      # Save strategy\n",
    "        # \"evaluation_strategy\": \"epoch\" # Evaluation strategy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c61d5d7-578e-4f9a-b34d-7f9b107ddbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/12/25 16:45:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> <span style=\"color: #d7af00; text-decoration-color: #d7af00\">s3_training_data_path</span>=<span style=\"color: #e100e1; text-decoration-color: #e100e1\">s3</span>:<span style=\"color: #e100e1; text-decoration-color: #e100e1\">//league-of-llm-internal-bucket-group3/domor</span> <a href=\"file:///tmp/ipykernel_7705/1981967332.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981967332.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_7705/1981967332.py#12\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #e100e1; text-decoration-color: #e100e1\">and/dataset/2025-03-12-dataset.jsonl</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/12/25 16:45:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m \u001b[38;2;215;175;0ms3_training_data_path\u001b[0m=\u001b[38;2;225;0;225ms3\u001b[0m:\u001b[38;2;225;0;225m/\u001b[0m\u001b[38;2;225;0;225m/league-of-llm-internal-bucket-group3/domor\u001b[0m \u001b]8;id=212515;file:///tmp/ipykernel_7705/1981967332.py\u001b\\\u001b[2m1981967332.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=926;file:///tmp/ipykernel_7705/1981967332.py#12\u001b\\\u001b[2m12\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;225;0;225mand/dataset/\u001b[0m\u001b[38;2;225;0;225m2025-03-12-dataset.jsonl\u001b[0m                                  \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Created JumpStart estimator for                                       <a href=\"file:///tmp/ipykernel_7705/1981967332.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981967332.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_7705/1981967332.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         meta-textgeneration-llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-3b-instruct                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Created JumpStart estimator for                                       \u001b]8;id=651133;file:///tmp/ipykernel_7705/1981967332.py\u001b\\\u001b[2m1981967332.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=774877;file:///tmp/ipykernel_7705/1981967332.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         meta-textgeneration-llama-\u001b[1;36m3\u001b[0m-\u001b[1;36m2\u001b[0m-3b-instruct                             \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Parameters <span style=\"font-weight: bold\">{</span><span style=\"color: #008700; text-decoration-color: #008700\">'epoch'</span>: <span style=\"color: #008700; text-decoration-color: #008700\">'3'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'learning_rate'</span>: <span style=\"color: #008700; text-decoration-color: #008700\">'0.00002'</span>,                 <a href=\"file:///tmp/ipykernel_7705/1981967332.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981967332.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_7705/1981967332.py#39\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008700; text-decoration-color: #008700\">'per_device_train_batch_size'</span>: <span style=\"color: #008700; text-decoration-color: #008700\">'4'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'gradient_accumulation_steps'</span>:    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008700; text-decoration-color: #008700\">'2'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'chat_dataset'</span>: <span style=\"color: #d70000; text-decoration-color: #d70000; font-style: italic\">False</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'instruction_tuned'</span>: <span style=\"color: #008700; text-decoration-color: #008700; font-style: italic\">True</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'lora_r'</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008700; text-decoration-color: #008700\">'16'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'lora_alpha'</span>: <span style=\"color: #008700; text-decoration-color: #008700\">'32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'lora_dropout'</span>: <span style=\"color: #008700; text-decoration-color: #008700\">'0.05'</span><span style=\"font-weight: bold\">}</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Parameters \u001b[1m{\u001b[0m\u001b[38;2;0;135;0m'epoch'\u001b[0m: \u001b[38;2;0;135;0m'3'\u001b[0m, \u001b[38;2;0;135;0m'learning_rate'\u001b[0m: \u001b[38;2;0;135;0m'0.00002'\u001b[0m,                 \u001b]8;id=814162;file:///tmp/ipykernel_7705/1981967332.py\u001b\\\u001b[2m1981967332.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=861175;file:///tmp/ipykernel_7705/1981967332.py#39\u001b\\\u001b[2m39\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;0;135;0m'per_device_train_batch_size'\u001b[0m: \u001b[38;2;0;135;0m'4'\u001b[0m, \u001b[38;2;0;135;0m'gradient_accumulation_steps'\u001b[0m:    \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;0;135;0m'2'\u001b[0m, \u001b[38;2;0;135;0m'chat_dataset'\u001b[0m: \u001b[3;38;2;215;0;0mFalse\u001b[0m, \u001b[38;2;0;135;0m'instruction_tuned'\u001b[0m: \u001b[3;38;2;0;135;0mTrue\u001b[0m, \u001b[38;2;0;135;0m'lora_r'\u001b[0m:      \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[38;2;0;135;0m'16'\u001b[0m, \u001b[38;2;0;135;0m'lora_alpha'\u001b[0m: \u001b[38;2;0;135;0m'32'\u001b[0m, \u001b[38;2;0;135;0m'lora_dropout'\u001b[0m: \u001b[38;2;0;135;0m'0.05'\u001b[0m\u001b[1m}\u001b[0m                     \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Starting fine-tuning job: group3-domorand-model-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202503121645</span>          <a href=\"file:///tmp/ipykernel_7705/1981967332.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981967332.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_7705/1981967332.py#49\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Starting fine-tuning job: group3-domorand-model-\u001b[1;36m202503121645\u001b[0m          \u001b]8;id=214712;file:///tmp/ipykernel_7705/1981967332.py\u001b\\\u001b[2m1981967332.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=947791;file:///tmp/ipykernel_7705/1981967332.py#49\u001b\\\u001b[2m49\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=658663;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=386871;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: group3-domorand-model-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202503121645</span>    <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: group3-domorand-model-\u001b[1;36m202503121645\u001b[0m    \u001b]8;id=219671;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=857461;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Training job started: group3-domorand-model-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202503121645</span>              <a href=\"file:///tmp/ipykernel_7705/1981967332.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981967332.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_7705/1981967332.py#57\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Training job started: group3-domorand-model-\u001b[1;36m202503121645\u001b[0m              \u001b]8;id=481599;file:///tmp/ipykernel_7705/1981967332.py\u001b\\\u001b[2m1981967332.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=694187;file:///tmp/ipykernel_7705/1981967332.py#57\u001b\\\u001b[2m57\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job 'group3-domorand-model-202503121645' started!\n",
      "You can monitor the job in the SageMaker console or run 'estimator.latest_training_job.wait()' to wait for completion\n",
      "response: {'job_name': 'group3-domorand-model-202503121645', 'model_data_s3_path': 's3://league-of-llm-internal-bucket-group3/domorand/output/group3-domorand-model-202503121645/output/model.tar.gz', 'training_job_arn': 'group3-domorand-model-202503121645'}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Get the current timestamp\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the timestamp as 'YYYYMMddHHmm'\n",
    "formatted_timestamp = current_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "response = run_llama_finetuning(f\"group3-domorand-model-{formatted_timestamp}\",\n",
    "                                \"2025-03-12-dataset.jsonl\", \n",
    "                                hyperparameters=small_dataset_1_hyperparameters)\n",
    "print(f\"response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f269d-9b13-4d2c-b17a-ed75565f11d5",
   "metadata": {},
   "source": [
    "## How to get previous job hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed38acc3-c53f-4446-97ea-2140a51d0747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"TrainingJobName\": \"group3-domorand-model-202503121618\",\n",
      "    \"TrainingJobArn\": \"arn:aws:sagemaker:us-east-1:482018956800:training-job/group3-domorand-model-202503121618\",\n",
      "    \"ModelArtifacts\": {\n",
      "        \"S3ModelArtifacts\": \"s3://league-of-llm-internal-bucket-group3/domorand/dataset/output/group3-domorand-model-202503121618/output/model\"\n",
      "    },\n",
      "    \"TrainingJobStatus\": \"Failed\",\n",
      "    \"SecondaryStatus\": \"Failed\",\n",
      "    \"FailureReason\": \"AlgorithmError: ExecuteUserScriptError:\\nExitCode 1\\nErrorMessage \\\"TypeError: expected str, bytes or os.PathLike object, not NoneType\\\"\\nCommand \\\"/opt/conda/bin/python3.10 transfer_learning.py --add_input_output_demarcation_key True --chat_dataset False --chat_template Llama3.1 --enable_fsdp True --epoch 3 --gradient_accumulation_steps 2 --instruction_tuned True --int8_quantization False --learning_rate 0.00002 --lora_alpha 32 --lora_dropout 0.05 --lora_r 16 --max_input_length -1 --max_seq_length 2048 --max_train_samples -1 --max_val_samples -1 --per_device_eval_batch_size 1 --per_device_train_batch_size 4 --preprocessing_num_workers None --seed 10 --target_modules q_proj,v_proj --train_data_split_seed 0 --validation_split_ratio 0.2\\\", exit code: 1\",\n",
      "    \"HyperParameters\": {\n",
      "        \"add_input_output_demarcation_key\": \"\\\"True\\\"\",\n",
      "        \"chat_dataset\": \"false\",\n",
      "        \"chat_template\": \"\\\"Llama3.1\\\"\",\n",
      "        \"enable_fsdp\": \"\\\"True\\\"\",\n",
      "        \"epoch\": \"\\\"3\\\"\",\n",
      "        \"gradient_accumulation_steps\": \"\\\"2\\\"\",\n",
      "        \"instruction_tuned\": \"true\",\n",
      "        \"int8_quantization\": \"\\\"False\\\"\",\n",
      "        \"learning_rate\": \"\\\"0.00002\\\"\",\n",
      "        \"lora_alpha\": \"\\\"32\\\"\",\n",
      "        \"lora_dropout\": \"\\\"0.05\\\"\",\n",
      "        \"lora_r\": \"\\\"16\\\"\",\n",
      "        \"max_input_length\": \"\\\"-1\\\"\",\n",
      "        \"max_seq_length\": \"\\\"2048\\\"\",\n",
      "        \"max_train_samples\": \"\\\"-1\\\"\",\n",
      "        \"max_val_samples\": \"\\\"-1\\\"\",\n",
      "        \"per_device_eval_batch_size\": \"\\\"1\\\"\",\n",
      "        \"per_device_train_batch_size\": \"\\\"4\\\"\",\n",
      "        \"preprocessing_num_workers\": \"\\\"None\\\"\",\n",
      "        \"sagemaker_container_log_level\": \"20\",\n",
      "        \"sagemaker_job_name\": \"\\\"group3-domorand-model-202503121618\\\"\",\n",
      "        \"sagemaker_program\": \"\\\"transfer_learning.py\\\"\",\n",
      "        \"sagemaker_region\": \"\\\"us-east-1\\\"\",\n",
      "        \"sagemaker_submit_directory\": \"\\\"/opt/ml/input/data/code/sourcedir.tar.gz\\\"\",\n",
      "        \"seed\": \"\\\"10\\\"\",\n",
      "        \"target_modules\": \"\\\"q_proj,v_proj\\\"\",\n",
      "        \"train_data_split_seed\": \"\\\"0\\\"\",\n",
      "        \"validation_split_ratio\": \"\\\"0.2\\\"\"\n",
      "    },\n",
      "    \"AlgorithmSpecification\": {\n",
      "        \"TrainingImage\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\",\n",
      "        \"TrainingInputMode\": \"File\",\n",
      "        \"MetricDefinitions\": [\n",
      "            {\n",
      "                \"Name\": \"huggingface-textgeneration:eval-loss\",\n",
      "                \"Regex\": \"eval_epoch_loss=tensor\\\\(([0-9\\\\.]+)\"\n",
      "            },\n",
      "            {\n",
      "                \"Name\": \"huggingface-textgeneration:eval-ppl\",\n",
      "                \"Regex\": \"eval_ppl=tensor\\\\(([0-9\\\\.]+)\"\n",
      "            },\n",
      "            {\n",
      "                \"Name\": \"huggingface-textgeneration:train-loss\",\n",
      "                \"Regex\": \"train_epoch_loss=([0-9\\\\.]+)\"\n",
      "            }\n",
      "        ],\n",
      "        \"EnableSageMakerMetricsTimeSeries\": false\n",
      "    },\n",
      "    \"RoleArn\": \"arn:aws:iam::482018956800:role/MonitoringStack-SageMakerExecutionRole7843F3B8-7FDMd6X85xyx\",\n",
      "    \"InputDataConfig\": [\n",
      "        {\n",
      "            \"ChannelName\": \"train\",\n",
      "            \"DataSource\": {\n",
      "                \"S3DataSource\": {\n",
      "                    \"S3DataType\": \"S3Prefix\",\n",
      "                    \"S3Uri\": \"s3://league-of-llm-internal-bucket-group3/domorand/dataset/2025-03-12-dataset.jsonl\",\n",
      "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
      "                }\n",
      "            },\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        {\n",
      "            \"ChannelName\": \"code\",\n",
      "            \"DataSource\": {\n",
      "                \"S3DataSource\": {\n",
      "                    \"S3DataType\": \"S3Prefix\",\n",
      "                    \"S3Uri\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/training/meta-textgeneration/prepack/inference-meta-textgeneration/v1.2.0/sourcedir.tar.gz\",\n",
      "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
      "                }\n",
      "            },\n",
      "            \"CompressionType\": \"None\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    ],\n",
      "    \"OutputDataConfig\": {\n",
      "        \"KmsKeyId\": \"\",\n",
      "        \"S3OutputPath\": \"s3://league-of-llm-internal-bucket-group3/domorand/dataset/output\",\n",
      "        \"CompressionType\": \"NONE\"\n",
      "    },\n",
      "    \"ResourceConfig\": {\n",
      "        \"InstanceType\": \"ml.g5.12xlarge\",\n",
      "        \"InstanceCount\": 1,\n",
      "        \"VolumeSizeInGB\": 30\n",
      "    },\n",
      "    \"StoppingCondition\": {\n",
      "        \"MaxRuntimeInSeconds\": 360000\n",
      "    },\n",
      "    \"CreationTime\": \"2025-03-12 16:18:58.340000+00:00\",\n",
      "    \"TrainingStartTime\": \"2025-03-12 16:23:00.545000+00:00\",\n",
      "    \"TrainingEndTime\": \"2025-03-12 16:29:17.229000+00:00\",\n",
      "    \"LastModifiedTime\": \"2025-03-12 16:29:17.561000+00:00\",\n",
      "    \"SecondaryStatusTransitions\": [\n",
      "        {\n",
      "            \"Status\": \"Starting\",\n",
      "            \"StartTime\": \"2025-03-12 16:18:58.340000+00:00\",\n",
      "            \"EndTime\": \"2025-03-12 16:18:58.695000+00:00\",\n",
      "            \"StatusMessage\": \"Starting the training job\"\n",
      "        },\n",
      "        {\n",
      "            \"Status\": \"Pending\",\n",
      "            \"StartTime\": \"2025-03-12 16:18:58.695000+00:00\",\n",
      "            \"EndTime\": \"2025-03-12 16:23:00.545000+00:00\",\n",
      "            \"StatusMessage\": \"Preparing the instances for training\"\n",
      "        },\n",
      "        {\n",
      "            \"Status\": \"Downloading\",\n",
      "            \"StartTime\": \"2025-03-12 16:23:00.545000+00:00\",\n",
      "            \"EndTime\": \"2025-03-12 16:26:53.340000+00:00\",\n",
      "            \"StatusMessage\": \"Downloading the training image\"\n",
      "        },\n",
      "        {\n",
      "            \"Status\": \"Training\",\n",
      "            \"StartTime\": \"2025-03-12 16:26:53.340000+00:00\",\n",
      "            \"EndTime\": \"2025-03-12 16:29:14.625000+00:00\",\n",
      "            \"StatusMessage\": \"Training image download completed. Training in progress.\"\n",
      "        },\n",
      "        {\n",
      "            \"Status\": \"Uploading\",\n",
      "            \"StartTime\": \"2025-03-12 16:29:14.625000+00:00\",\n",
      "            \"EndTime\": \"2025-03-12 16:29:17.229000+00:00\",\n",
      "            \"StatusMessage\": \"Uploading generated training model\"\n",
      "        },\n",
      "        {\n",
      "            \"Status\": \"Failed\",\n",
      "            \"StartTime\": \"2025-03-12 16:29:17.229000+00:00\",\n",
      "            \"EndTime\": \"2025-03-12 16:29:17.229000+00:00\",\n",
      "            \"StatusMessage\": \"Training job failed\"\n",
      "        }\n",
      "    ],\n",
      "    \"FinalMetricDataList\": [],\n",
      "    \"EnableNetworkIsolation\": true,\n",
      "    \"EnableInterContainerTrafficEncryption\": true,\n",
      "    \"EnableManagedSpotTraining\": false,\n",
      "    \"TrainingTimeInSeconds\": 377,\n",
      "    \"BillableTimeInSeconds\": 377,\n",
      "    \"DebugHookConfig\": {\n",
      "        \"S3OutputPath\": \"s3://league-of-llm-internal-bucket-group3/domorand/dataset/output\",\n",
      "        \"CollectionConfigurations\": []\n",
      "    },\n",
      "    \"ProfilerConfig\": {\n",
      "        \"S3OutputPath\": \"s3://league-of-llm-internal-bucket-group3/domorand/dataset/output\",\n",
      "        \"ProfilingIntervalInMilliseconds\": 500,\n",
      "        \"DisableProfiler\": false\n",
      "    },\n",
      "    \"ProfilingStatus\": \"Enabled\",\n",
      "    \"Environment\": {},\n",
      "    \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"ad8f7dc9-ef9b-4d67-a956-10baef991d78\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "            \"x-amzn-requestid\": \"ad8f7dc9-ef9b-4d67-a956-10baef991d78\",\n",
      "            \"content-type\": \"application/x-amz-json-1.1\",\n",
      "            \"content-length\": \"5625\",\n",
      "            \"date\": \"Wed, 12 Mar 2025 16:33:56 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "    }\n",
      "}\n",
      "{'TrainingJobName': 'group3-domorand-model-202503121618', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:482018956800:training-job/group3-domorand-model-202503121618', 'ModelArtifacts': {'S3ModelArtifacts': 's3://league-of-llm-internal-bucket-group3/domorand/dataset/output/group3-domorand-model-202503121618/output/model'}, 'TrainingJobStatus': 'Failed', 'SecondaryStatus': 'Failed', 'FailureReason': 'AlgorithmError: ExecuteUserScriptError:\\nExitCode 1\\nErrorMessage \"TypeError: expected str, bytes or os.PathLike object, not NoneType\"\\nCommand \"/opt/conda/bin/python3.10 transfer_learning.py --add_input_output_demarcation_key True --chat_dataset False --chat_template Llama3.1 --enable_fsdp True --epoch 3 --gradient_accumulation_steps 2 --instruction_tuned True --int8_quantization False --learning_rate 0.00002 --lora_alpha 32 --lora_dropout 0.05 --lora_r 16 --max_input_length -1 --max_seq_length 2048 --max_train_samples -1 --max_val_samples -1 --per_device_eval_batch_size 1 --per_device_train_batch_size 4 --preprocessing_num_workers None --seed 10 --target_modules q_proj,v_proj --train_data_split_seed 0 --validation_split_ratio 0.2\", exit code: 1', 'HyperParameters': {'add_input_output_demarcation_key': '\"True\"', 'chat_dataset': 'false', 'chat_template': '\"Llama3.1\"', 'enable_fsdp': '\"True\"', 'epoch': '\"3\"', 'gradient_accumulation_steps': '\"2\"', 'instruction_tuned': 'true', 'int8_quantization': '\"False\"', 'learning_rate': '\"0.00002\"', 'lora_alpha': '\"32\"', 'lora_dropout': '\"0.05\"', 'lora_r': '\"16\"', 'max_input_length': '\"-1\"', 'max_seq_length': '\"2048\"', 'max_train_samples': '\"-1\"', 'max_val_samples': '\"-1\"', 'per_device_eval_batch_size': '\"1\"', 'per_device_train_batch_size': '\"4\"', 'preprocessing_num_workers': '\"None\"', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"group3-domorand-model-202503121618\"', 'sagemaker_program': '\"transfer_learning.py\"', 'sagemaker_region': '\"us-east-1\"', 'sagemaker_submit_directory': '\"/opt/ml/input/data/code/sourcedir.tar.gz\"', 'seed': '\"10\"', 'target_modules': '\"q_proj,v_proj\"', 'train_data_split_seed': '\"0\"', 'validation_split_ratio': '\"0.2\"'}, 'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04', 'TrainingInputMode': 'File', 'MetricDefinitions': [{'Name': 'huggingface-textgeneration:eval-loss', 'Regex': 'eval_epoch_loss=tensor\\\\(([0-9\\\\.]+)'}, {'Name': 'huggingface-textgeneration:eval-ppl', 'Regex': 'eval_ppl=tensor\\\\(([0-9\\\\.]+)'}, {'Name': 'huggingface-textgeneration:train-loss', 'Regex': 'train_epoch_loss=([0-9\\\\.]+)'}], 'EnableSageMakerMetricsTimeSeries': False}, 'RoleArn': 'arn:aws:iam::482018956800:role/MonitoringStack-SageMakerExecutionRole7843F3B8-7FDMd6X85xyx', 'InputDataConfig': [{'ChannelName': 'train', 'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://league-of-llm-internal-bucket-group3/domorand/dataset/2025-03-12-dataset.jsonl', 'S3DataDistributionType': 'FullyReplicated'}}, 'CompressionType': 'None', 'RecordWrapperType': 'None'}, {'ChannelName': 'code', 'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/training/meta-textgeneration/prepack/inference-meta-textgeneration/v1.2.0/sourcedir.tar.gz', 'S3DataDistributionType': 'FullyReplicated'}}, 'CompressionType': 'None', 'RecordWrapperType': 'None'}], 'OutputDataConfig': {'KmsKeyId': '', 'S3OutputPath': 's3://league-of-llm-internal-bucket-group3/domorand/dataset/output', 'CompressionType': 'NONE'}, 'ResourceConfig': {'InstanceType': 'ml.g5.12xlarge', 'InstanceCount': 1, 'VolumeSizeInGB': 30}, 'StoppingCondition': {'MaxRuntimeInSeconds': 360000}, 'CreationTime': datetime.datetime(2025, 3, 12, 16, 18, 58, 340000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2025, 3, 12, 16, 23, 0, 545000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2025, 3, 12, 16, 29, 17, 229000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2025, 3, 12, 16, 29, 17, 561000, tzinfo=tzlocal()), 'SecondaryStatusTransitions': [{'Status': 'Starting', 'StartTime': datetime.datetime(2025, 3, 12, 16, 18, 58, 340000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2025, 3, 12, 16, 18, 58, 695000, tzinfo=tzlocal()), 'StatusMessage': 'Starting the training job'}, {'Status': 'Pending', 'StartTime': datetime.datetime(2025, 3, 12, 16, 18, 58, 695000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2025, 3, 12, 16, 23, 0, 545000, tzinfo=tzlocal()), 'StatusMessage': 'Preparing the instances for training'}, {'Status': 'Downloading', 'StartTime': datetime.datetime(2025, 3, 12, 16, 23, 0, 545000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2025, 3, 12, 16, 26, 53, 340000, tzinfo=tzlocal()), 'StatusMessage': 'Downloading the training image'}, {'Status': 'Training', 'StartTime': datetime.datetime(2025, 3, 12, 16, 26, 53, 340000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2025, 3, 12, 16, 29, 14, 625000, tzinfo=tzlocal()), 'StatusMessage': 'Training image download completed. Training in progress.'}, {'Status': 'Uploading', 'StartTime': datetime.datetime(2025, 3, 12, 16, 29, 14, 625000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2025, 3, 12, 16, 29, 17, 229000, tzinfo=tzlocal()), 'StatusMessage': 'Uploading generated training model'}, {'Status': 'Failed', 'StartTime': datetime.datetime(2025, 3, 12, 16, 29, 17, 229000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2025, 3, 12, 16, 29, 17, 229000, tzinfo=tzlocal()), 'StatusMessage': 'Training job failed'}], 'FinalMetricDataList': [], 'EnableNetworkIsolation': True, 'EnableInterContainerTrafficEncryption': True, 'EnableManagedSpotTraining': False, 'TrainingTimeInSeconds': 377, 'BillableTimeInSeconds': 377, 'DebugHookConfig': {'S3OutputPath': 's3://league-of-llm-internal-bucket-group3/domorand/dataset/output', 'CollectionConfigurations': []}, 'ProfilerConfig': {'S3OutputPath': 's3://league-of-llm-internal-bucket-group3/domorand/dataset/output', 'ProfilingIntervalInMilliseconds': 500, 'DisableProfiler': False}, 'ProfilingStatus': 'Enabled', 'Environment': {}, 'ResponseMetadata': {'RequestId': 'ad8f7dc9-ef9b-4d67-a956-10baef991d78', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ad8f7dc9-ef9b-4d67-a956-10baef991d78', 'content-type': 'application/x-amz-json-1.1', 'content-length': '5625', 'date': 'Wed, 12 Mar 2025 16:33:56 GMT'}, 'RetryAttempts': 0}}\n",
      "{\n",
      "    \"add_input_output_demarcation_key\": \"\\\"True\\\"\",\n",
      "    \"chat_dataset\": \"false\",\n",
      "    \"chat_template\": \"\\\"Llama3.1\\\"\",\n",
      "    \"enable_fsdp\": \"\\\"True\\\"\",\n",
      "    \"epoch\": \"\\\"3\\\"\",\n",
      "    \"gradient_accumulation_steps\": \"\\\"2\\\"\",\n",
      "    \"instruction_tuned\": \"true\",\n",
      "    \"int8_quantization\": \"\\\"False\\\"\",\n",
      "    \"learning_rate\": \"\\\"0.00002\\\"\",\n",
      "    \"lora_alpha\": \"\\\"32\\\"\",\n",
      "    \"lora_dropout\": \"\\\"0.05\\\"\",\n",
      "    \"lora_r\": \"\\\"16\\\"\",\n",
      "    \"max_input_length\": \"\\\"-1\\\"\",\n",
      "    \"max_seq_length\": \"\\\"2048\\\"\",\n",
      "    \"max_train_samples\": \"\\\"-1\\\"\",\n",
      "    \"max_val_samples\": \"\\\"-1\\\"\",\n",
      "    \"per_device_eval_batch_size\": \"\\\"1\\\"\",\n",
      "    \"per_device_train_batch_size\": \"\\\"4\\\"\",\n",
      "    \"preprocessing_num_workers\": \"\\\"None\\\"\",\n",
      "    \"sagemaker_container_log_level\": \"20\",\n",
      "    \"sagemaker_job_name\": \"\\\"group3-domorand-model-202503121618\\\"\",\n",
      "    \"sagemaker_program\": \"\\\"transfer_learning.py\\\"\",\n",
      "    \"sagemaker_region\": \"\\\"us-east-1\\\"\",\n",
      "    \"sagemaker_submit_directory\": \"\\\"/opt/ml/input/data/code/sourcedir.tar.gz\\\"\",\n",
      "    \"seed\": \"\\\"10\\\"\",\n",
      "    \"target_modules\": \"\\\"q_proj,v_proj\\\"\",\n",
      "    \"train_data_split_seed\": \"\\\"0\\\"\",\n",
      "    \"validation_split_ratio\": \"\\\"0.2\\\"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Specify the training job name\n",
    "# training_job_name = 'group3-domorand-model13'\n",
    "training_job_name = 'group3-domorand-model-202503121618'\n",
    "\n",
    "# Describe the training job\n",
    "response = sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "# Access hyperparameters\n",
    "# Pretty print the response\n",
    "print(json.dumps(response, indent=4, default=str))\n",
    "# print(response)\n",
    "# print(json.dumps(response['HyperParameters'], indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
